import os
import torch
import logging
import re
import yaml
import argparse
import shutil
from glob import glob

def get_args():
    parser = argparse.ArgumentParser(description="10best Average Model Creator")
    parser.add_argument("--model_dir", required=True, help="Directory containing model checkpoints")
    parser.add_argument("--output_path", default="10best_avg.pt", help="Output path for the averaged model")
    parser.add_argument("--top_k", type=int, default=10, help="Number of best checkpoints to average")
    return parser.parse_args()

def read_latest_cv_losses(latest_yaml_path):
    """  
    `latest.yaml`ì—ì„œ `cv_losses` ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ ë°˜í™˜  
    """
    if not os.path.exists(latest_yaml_path):
        logging.error(f"âŒ latest.yaml not found at {latest_yaml_path}!")
        return None, None

    with open(latest_yaml_path, "r") as f:
        data = yaml.safe_load(f)

    cv_losses = data.get("cv_losses", [])
    epoch = data.get("epoch", None)

    if not cv_losses or epoch is None:
        logging.error("âŒ No valid `cv_losses` or `epoch` found in latest.yaml!")
        return None, None

    return cv_losses, epoch

def average_checkpoints(model_dir, output_path, top_k=10):
    """
    ğŸ”¥ `latest.yaml`ì—ì„œ `cv_losses`ë¥¼ ì½ì–´ ê°€ì¥ ì¢‹ì€ `top_k` ê°œ ì²´í¬í¬ì¸íŠ¸ í‰ê·   
    """
    latest_yaml_path = os.path.join(model_dir, "latest.yaml")
    cv_losses, total_epochs = read_latest_cv_losses(latest_yaml_path)

    if cv_losses is None:
        logging.error("âŒ Cannot proceed without `cv_losses` data!")
        return []

    # ğŸ”¥ 1ï¸âƒ£ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸(.pt) íŒŒì¼ ê°€ì ¸ì˜¤ê¸°  
    checkpoints = glob(os.path.join(model_dir, "*.pt"))
    if not checkpoints:
        logging.error("âŒ No checkpoint files found in model directory!")
        return []

    # ğŸ”¥ 2ï¸âƒ£ ìµœì‹  `epoch` ê°’ì— ë”°ë¼ ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ ì˜ˆì¸¡ (`<epoch>.pt` í˜•íƒœ)  
    epoch_to_ckpt = {int(re.search(r"(\d+).pt$", ckpt).group(1)): ckpt for ckpt in checkpoints if re.search(r"(\d+).pt$", ckpt)}

    # ğŸ”¥ 3ï¸âƒ£ ìµœì‹  `cv_losses` ë¦¬ìŠ¤íŠ¸ì™€ `epoch`ë¥¼ ë§¤ì¹­  
    valid_checkpoints = [(epoch_to_ckpt[i + 1], cv_losses[i]) for i in range(len(cv_losses)) if (i + 1) in epoch_to_ckpt]

    if not valid_checkpoints:
        logging.error("âŒ No valid checkpoints matched with cv_losses!")
        return []

    # ğŸ”¥ 4ï¸âƒ£ `cv_loss`ê°€ ì‘ì€ `top_k` ê°œ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ  
    valid_checkpoints.sort(key=lambda x: x[1])  # ì‘ì€ `cv_loss`ê°€ ìš°ì„   
    top_checkpoints = valid_checkpoints[:top_k]
    used_checkpoints = [ckpt[0] for ckpt in top_checkpoints]

    logging.info(f"âœ… Averaging the following checkpoints: {used_checkpoints}")

    # ğŸ”¥ 5ï¸âƒ£ ëª¨ë¸ ê°€ì¤‘ì¹˜ í‰ê·  ê³„ì‚°  
    avg_state_dict = None
    for ckpt_path, _ in top_checkpoints:
        state_dict = torch.load(ckpt_path, map_location="cpu")
        if avg_state_dict is None:
            avg_state_dict = {k: torch.zeros_like(v, dtype=torch.float32) for k, v in state_dict.items()}
        for k, v in state_dict.items():
            avg_state_dict[k] += v.float() / top_k  # í‰ê·  ê³„ì‚°  

    # ğŸ”¥ 6ï¸âƒ£ í‰ê·  ëª¨ë¸ ì €ì¥  
    torch.save(avg_state_dict, output_path)
    logging.info(f"âœ… Averaged model saved to {output_path}")

    return used_checkpoints
    
def cleanup_checkpoints(model_dir, keep_checkpoints):
    """
    ğŸ”¥ `latest.yaml`ê³¼ `10best_avg.pt`ë§Œ ìœ ì§€í•˜ê³ , ë‚˜ë¨¸ì§€ `.yaml`ì€ ì‚­ì œ
    """
    config_path = os.path.join(model_dir, "config.yaml")
    latest_yaml = os.path.join(model_dir, "latest.yaml")

    # ğŸ”¥ 1ï¸âƒ£ ìœ ì§€í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    keep_checkpoints.append(config_path)  # `config.yaml` ìœ ì§€
    keep_checkpoints.append(latest_yaml)  # `latest.yaml` ìœ ì§€

    # ğŸ”¥ 2ï¸âƒ£ ë¶ˆí•„ìš”í•œ `n.pt` ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
    all_checkpoints = glob(os.path.join(model_dir, "*.pt"))
    for ckpt in all_checkpoints:
        if ckpt not in keep_checkpoints:
            os.remove(ckpt)
            logging.info(f"ğŸ—‘ï¸ Deleted checkpoint: {ckpt}")

    # ğŸ”¥ 3ï¸âƒ£ ëª¨ë“  `.yaml` ì¤‘ `latest.yaml` ì œì™¸í•˜ê³  ì‚­ì œ
    all_yaml_files = glob(os.path.join(model_dir, "*.yaml"))
    for yaml_file in all_yaml_files:
        if yaml_file not in keep_checkpoints and yaml_file != latest_yaml:
            os.remove(yaml_file)
            logging.info(f"ğŸ—‘ï¸ Deleted YAML file: {yaml_file}")


def copy_latest_yaml(model_dir, output_path):
    """
    Copy latest.yaml to match the averaged model file.
    
    Args:
        model_dir (str): Path to the model directory.
        output_path (str): Path of the averaged model file.
    """
    latest_yaml = os.path.join(model_dir, "latest.yaml")
    output_yaml = re.sub(r"\.pt$", ".yaml", output_path)
    
    if os.path.exists(latest_yaml):
        shutil.copy(latest_yaml, output_yaml)
        logging.info(f"Copied {latest_yaml} to {output_yaml}")
    else:
        logging.warning("latest.yaml not found. Skipping copy.")

def main():
    # Parse arguments
    args = get_args()

    model_dir = args.model_dir
    output_path = os.path.join(model_dir, args.output_path)
    top_k = args.top_k

    # Average the top-k best checkpoints
    used_checkpoints = average_checkpoints(model_dir, output_path, top_k=top_k)

    # Keep only the used checkpoints and delete the rest
    cleanup_checkpoints(model_dir, keep_checkpoints=used_checkpoints + [output_path])

    # Ensure latest.yaml is copied for metadata preservation
    copy_latest_yaml(model_dir, output_path)

    logging.info("10best averaging and cleanup complete.")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    main()